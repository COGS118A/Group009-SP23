{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e66cbb9e",
   "metadata": {},
   "source": [
    "## Going towards neural networks\n",
    "\n",
    "In search of more complex models, we decided to also go towards neural networks.\n",
    "In binary classification, the input data typically flows through the layers of the model in a sequential manner, from the input layer to the output layer. The Sequential API is specifically designed for building models where the data flows sequentially through the layers, making it a natural choice for binary classification tasks.\n",
    "We found it by going through the library's documentation and thought it would be a good idea to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795577a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# for modeling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "def get_data():\n",
    "    url = 'https://raw.githubusercontent.com/COGS118A/Group009-SP23/main/clean_data.csv'\n",
    "    data = pd.read_csv(url)\n",
    "    data = data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05895789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = get_data()\n",
    "\n",
    "# Define predictors and labels\n",
    "X = data.drop('good_outcome', axis=1)\n",
    "y = data['good_outcome']\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a99a4",
   "metadata": {},
   "source": [
    "#### Defining the model\n",
    "\n",
    "Here's a breakdown of what each section does:\n",
    "\n",
    "* Model 1:\n",
    "This model has three layers: an input layer with 16 units and ReLU activation, a hidden layer with 16 units and ReLU activation, and an output layer with 1 unit and sigmoid activation.\n",
    "* Model 2:\n",
    "This model is similar to Model 1 but with an additional hidden layer.\n",
    "The second hidden layer has 32 units and ReLU activation, while the rest of the layers remain the same.\n",
    "* Model 3:\n",
    "In this model, the number of units in the existing layers is increased to 32.\n",
    "The first hidden layer now has 32 units, and the second hidden layer also has 32 units, while the output layer remains the same.\n",
    "* Model 4:\n",
    "Model 4 maintains the same architecture as Model 1 but changes the activation function.\n",
    "The activation function in both hidden layers is now set to \"tanh,\" which is the hyperbolic tangent function, while the output layer still uses the sigmoid activation.\n",
    "\n",
    "These variations in the model configurations allow for experimentation and exploration of different architectural choices, such as layer depth, number of units, and activation functions. By testing these different models, you can observe how the changes affect the model's capacity to learn and its performance on a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ca0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "def create_model1():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(16, input_shape=(X.shape[1],), activation='relu')) # Add an input shape! (features,)\n",
    "    model1.add(Dense(16, activation='relu'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "    model1.summary() \n",
    "    return model1\n",
    "\n",
    "def create_model2():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(16, input_shape=(X.shape[1],), activation='relu'))\n",
    "    model2.add(Dense(32, activation='relu'))  # Add an additional hidden layer\n",
    "    model2.add(Dense(16, activation='relu'))\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "    model2.summary()\n",
    "    return model2\n",
    "\n",
    "def create_model3():\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(32, input_shape=(X.shape[1],), activation='relu'))  # Increase units to 32\n",
    "    model3.add(Dense(32, activation='relu'))  # Increase units to 32\n",
    "    model3.add(Dense(1, activation='sigmoid'))\n",
    "    model3.summary()\n",
    "    return model3\n",
    "\n",
    "\n",
    "def create_model4():\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(16, input_shape=(X.shape[1],), activation='tanh'))  # Use 'tanh' activation\n",
    "    model4.add(Dense(16, activation='tanh'))\n",
    "    model4.add(Dense(1, activation='sigmoid'))\n",
    "    model4.summary()\n",
    "    return model4\n",
    "\n",
    "model1 = create_model1()\n",
    "model2 = create_model2()\n",
    "model3 = create_model3()\n",
    "model4 = create_model4()\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model4.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# early stopping callback\n",
    "# This callback will stop the training when there is no improvement in  \n",
    "# the validation loss for 10 consecutive epochs.  \n",
    "es = EarlyStopping(monitor='val_accuracy', \n",
    "                                   mode='max', # don't minimize the accuracy!\n",
    "                                   patience=10,\n",
    "                                   restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee9c9b",
   "metadata": {},
   "source": [
    "### Training the models \n",
    "\n",
    "During the training process, the models learn from the input data (X) and the corresponding target labels (y). The models optimize their internal parameters using the Adam optimizer, minimize the binary cross-entropy loss, and monitor the accuracy metric.\n",
    "\n",
    "The early stopping callback (es) is included to stop the training process if there is no improvement in validation accuracy for 10 consecutive epochs. By monitoring the validation accuracy, the callback helps prevent overfitting and allows the models to stop training early if they start to plateau in performance.\n",
    "\n",
    "The training histories (history1, history2, history3, history4) store information about the training progress, such as the loss and accuracy values for each epoch. This information can be used for analysis, visualization, and evaluating the models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc22054",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(X,\n",
    "                    y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80,\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d48d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X,\n",
    "                    y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(X,\n",
    "                    y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73b5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history4 = model4.fit(X,\n",
    "                    y,\n",
    "                    callbacks=[es],\n",
    "                    epochs=80, # you can set this to a big number!\n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b26b7",
   "metadata": {},
   "source": [
    "### Intermediate results\n",
    "\n",
    "We use learning curves to look at our results. We can see that model 1 and model 3 perform well comparing to model 2 and 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3dd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for multiple graphs\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Iterate over each model's history\n",
    "for i, (history, model_name) in enumerate([(history1, 'Model 1'), (history2, 'Model 2'), (history3, 'Model 3'), (history4, 'Model 4')]):\n",
    "    # Learning curve (Loss)\n",
    "    # Retrieve the training and validation loss values\n",
    "    loss_values = history.history['loss']\n",
    "    val_loss_values = history.history['val_loss']\n",
    "    \n",
    "    # Range of X (number of epochs)\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    \n",
    "    # Plot the training and validation loss for the current model\n",
    "    ax = axs[i//2, i%2]\n",
    "    ax.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "    ax.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot with all four graphs\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for multiple graphs\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Iterate over each model's history\n",
    "for i, (history, model_name) in enumerate([(history1, 'Model 1'), (history2, 'Model 2'), (history3, 'Model 3'), (history4, 'Model 4')]):\n",
    "    # Learning curve (Accuracy)\n",
    "    # Retrieve the training and validation accuracy values\n",
    "    acc_values = history.history['accuracy']\n",
    "    val_acc_values = history.history['val_accuracy']\n",
    "    \n",
    "    # Range of X (number of epochs)\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "    \n",
    "    # Plot the training and validation accuracy for the current model\n",
    "    ax = axs[i//2, i%2]\n",
    "    ax.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
    "    ax.plot(epochs, val_acc_values, 'orange', label='Validation accuracy')\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot with all four graphs\n",
    "plt.show()\n",
    "\n",
    "# Maximum validation accuracy\n",
    "max_val_acc = np.max([history.history['val_accuracy'] for history in [history1, history2, history3, history4]])\n",
    "print(\"Maximum validation accuracy:\", max_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Iterate over each model\n",
    "for i, (model, model_name) in enumerate([(model1, 'Model 1'), (model2, 'Model 2'), (model3, 'Model 3'), (model4, 'Model 4')]):\n",
    "    # Predict probabilities and round to 0 or 1\n",
    "    preds = np.round(model.predict(X), 0)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y, preds)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    \n",
    "    # Generate and print classification report\n",
    "    report = classification_report(y, preds)\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"-\" * 40)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffccb02d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a25a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad5654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c482a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31bd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c106febc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56eb498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bafe55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
